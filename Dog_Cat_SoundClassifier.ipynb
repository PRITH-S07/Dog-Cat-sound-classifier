{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog_Cat_SoundClassifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJwcgZ53bCkV"
      },
      "source": [
        "dataset='/content/drive/MyDrive/full_dataset'"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Zl-_eSEDB0"
      },
      "source": [
        "import struct\n",
        "\n",
        "class WavFileHelper():\n",
        "    \n",
        "    def read_file_properties(self, filename):\n",
        "\n",
        "        wave_file = open(filename,\"rb\")\n",
        "        \n",
        "        riff = wave_file.read(12)\n",
        "        fmt = wave_file.read(36)\n",
        "        \n",
        "        num_channels_string = fmt[10:12]\n",
        "        num_channels = struct.unpack('<H', num_channels_string)[0]\n",
        "\n",
        "        sample_rate_string = fmt[12:16]\n",
        "        sample_rate = struct.unpack(\"<I\",sample_rate_string)[0]\n",
        "        \n",
        "        bit_depth_string = fmt[22:24]\n",
        "        bit_depth = struct.unpack(\"<H\",bit_depth_string)[0]\n",
        "\n",
        "        return (num_channels, sample_rate, bit_depth)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU17oD4Dbu0b"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "wavfilehelper = WavFileHelper()\n",
        "audiodata=[]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTKrJhw8byi6"
      },
      "source": [
        "for i in os.listdir(dataset):\n",
        "  data = wavfilehelper.read_file_properties(dataset+\"/\"+i)\n",
        "  audiodata.append(data)\n",
        "audiodf = pd.DataFrame(audiodata, columns=['num_channels','sample_rate','bit_depth'])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-zFUuLUEZDh",
        "outputId": "73459f63-fbf3-4709-d2cf-b1538e98a87a"
      },
      "source": [
        "print(audiodf.num_channels.value_counts(normalize=True))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    1.0\n",
            "Name: num_channels, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lasxTCTE-k0",
        "outputId": "503f5956-517c-4bb6-ace2-4b9b54cead7d"
      },
      "source": [
        "print(audiodf.sample_rate.value_counts(normalize=True))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000    1.0\n",
            "Name: sample_rate, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_1BtKwLFKIO",
        "outputId": "17df421f-9424-4030-96be-9e7b861593fa"
      },
      "source": [
        "print(audiodf.bit_depth.value_counts(normalize=True))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16    1.0\n",
            "Name: bit_depth, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHABE0wNFT90"
      },
      "source": [
        "def extract_features(file_name):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file)\n",
        "        return None \n",
        "     \n",
        "    return mfccsscaled"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cYIEgUXXoQL",
        "outputId": "85357748-1c97-4967-bbac-aa859024161b"
      },
      "source": [
        "print(audiodf.head())"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   num_channels  sample_rate  bit_depth\n",
            "0             1        16000         16\n",
            "1             1        16000         16\n",
            "2             1        16000         16\n",
            "3             1        16000         16\n",
            "4             1        16000         16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHFHC3l_YGBS"
      },
      "source": [
        "features=[]\n",
        "import numpy as np\n",
        "for i in os.listdir(dataset):\n",
        "  class_label=i[:3]\n",
        "  data=extract_features(dataset+'/'+i)\n",
        "  features.append([data,class_label])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5qRclzCYaP-"
      },
      "source": [
        "df_features=pd.DataFrame(features,columns=['feature','class_label'])"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN09scCkZZTX"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(df_features.feature.tolist())\n",
        "y = np.array(df_features.class_label.tolist())\n",
        "\n",
        "# Encode the classification labels \n",
        "le = LabelEncoder()\n",
        "y2 = to_categorical(le.fit_transform(y)) \n",
        "\n",
        "# split the dataset \n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjXXqgpwZy5d",
        "outputId": "de9cb293-2862-4596-b47c-ebc43ebc4b5c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "X_train.shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(221, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwADamoDbego",
        "outputId": "619cfed5-18cb-4741-ae6d-0b2684df9496"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKmD4IVuangT"
      },
      "source": [
        "n_rows=40\n",
        "n_cols=1\n",
        "n_channels=1\n",
        "X_train=X_train.reshape(X_train.shape[0],n_rows,n_cols,n_channels)\n",
        "X_test=X_test.reshape(X_test.shape[0],n_rows,n_cols,n_channels)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJXvYGpge8Ec",
        "outputId": "e5a840cf-e501-4a3e-aff6-757dce36334c"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 40, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQfTh24rbNkG"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16,kernel_size=1, input_shape=(n_rows, n_cols, n_channels), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=1))\n",
        "model.add(Conv2D(filters=32, kernel_size=1, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=1))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoXrh39Wcvp1",
        "outputId": "6ec12ce8-d295-403e-ca07-d3daedf7ef67"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# Display model architecture summary \n",
        "model.summary()\n",
        "\n",
        "# Calculate pre-training accuracy \n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy) "
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_73 (Conv2D)           (None, 40, 1, 16)         32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_71 (MaxPooling (None, 40, 1, 16)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 40, 1, 32)         544       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_72 (MaxPooling (None, 40, 1, 32)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 3,138\n",
            "Trainable params: 3,138\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2150 - accuracy: 0.4821\n",
            "Pre-training accuracy: 48.2143%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1si20odFdEtr",
        "outputId": "198104cf-98c5-4c8d-bad3-70a20c0ae35f"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint \n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 50\n",
        "num_batch_size = 8\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.9757 - accuracy: 0.6516 - val_loss: 0.3493 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.34931, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
            "Epoch 2/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.8371 - val_loss: 0.4639 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.34931\n",
            "Epoch 3/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8778 - val_loss: 0.2867 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.34931 to 0.28668, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
            "Epoch 4/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8643 - val_loss: 0.2411 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.28668 to 0.24112, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
            "Epoch 5/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8778 - val_loss: 0.4708 - val_accuracy: 0.8393\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.24112\n",
            "Epoch 6/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8688 - val_loss: 0.3078 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.24112\n",
            "Epoch 7/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.8778 - val_loss: 0.3752 - val_accuracy: 0.8214\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.24112\n",
            "Epoch 8/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9140 - val_loss: 0.4953 - val_accuracy: 0.8393\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.24112\n",
            "Epoch 9/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9005 - val_loss: 0.2919 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.24112\n",
            "Epoch 10/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2176 - accuracy: 0.9321 - val_loss: 0.3219 - val_accuracy: 0.8393\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.24112\n",
            "Epoch 11/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9140 - val_loss: 0.3374 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.24112\n",
            "Epoch 12/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.9276 - val_loss: 0.3377 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.24112\n",
            "Epoch 13/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2232 - accuracy: 0.9095 - val_loss: 0.3596 - val_accuracy: 0.8214\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.24112\n",
            "Epoch 14/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9412 - val_loss: 0.2911 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.24112\n",
            "Epoch 15/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9276 - val_loss: 0.3139 - val_accuracy: 0.8393\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.24112\n",
            "Epoch 16/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2084 - accuracy: 0.9276 - val_loss: 0.5228 - val_accuracy: 0.7679\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.24112\n",
            "Epoch 17/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9276 - val_loss: 0.4277 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.24112\n",
            "Epoch 18/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1964 - accuracy: 0.9231 - val_loss: 0.3323 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.24112\n",
            "Epoch 19/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.9186 - val_loss: 0.3509 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.24112\n",
            "Epoch 20/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9548 - val_loss: 0.3374 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.24112\n",
            "Epoch 21/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9321 - val_loss: 0.4299 - val_accuracy: 0.8214\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.24112\n",
            "Epoch 22/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9095 - val_loss: 0.4711 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.24112\n",
            "Epoch 23/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9276 - val_loss: 0.3394 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.24112\n",
            "Epoch 24/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9502 - val_loss: 0.4488 - val_accuracy: 0.8214\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.24112\n",
            "Epoch 25/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2057 - accuracy: 0.9050 - val_loss: 0.3870 - val_accuracy: 0.8214\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.24112\n",
            "Epoch 26/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9186 - val_loss: 0.4090 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.24112\n",
            "Epoch 27/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9502 - val_loss: 0.4054 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.24112\n",
            "Epoch 28/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9502 - val_loss: 0.4140 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.24112\n",
            "Epoch 29/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9502 - val_loss: 0.4542 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.24112\n",
            "Epoch 30/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9683 - val_loss: 0.4267 - val_accuracy: 0.8393\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.24112\n",
            "Epoch 31/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9774 - val_loss: 0.4006 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.24112\n",
            "Epoch 32/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1140 - accuracy: 0.9593 - val_loss: 0.5758 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.24112\n",
            "Epoch 33/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9457 - val_loss: 0.4309 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.24112\n",
            "Epoch 34/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9548 - val_loss: 0.4036 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.24112\n",
            "Epoch 35/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9683 - val_loss: 0.4077 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.24112\n",
            "Epoch 36/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9774 - val_loss: 0.4051 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.24112\n",
            "Epoch 37/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9864 - val_loss: 0.3925 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.24112\n",
            "Epoch 38/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9864 - val_loss: 0.4259 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.24112\n",
            "Epoch 39/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9638 - val_loss: 0.3782 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.24112\n",
            "Epoch 40/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9683 - val_loss: 0.4446 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.24112\n",
            "Epoch 41/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 0.4327 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.24112\n",
            "Epoch 42/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9729 - val_loss: 0.3949 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.24112\n",
            "Epoch 43/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9910 - val_loss: 0.4479 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.24112\n",
            "Epoch 44/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.4254 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.24112\n",
            "Epoch 45/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9910 - val_loss: 0.4707 - val_accuracy: 0.8393\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.24112\n",
            "Epoch 46/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.4394 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.24112\n",
            "Epoch 47/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9864 - val_loss: 0.4646 - val_accuracy: 0.8929\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.24112\n",
            "Epoch 48/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.24112\n",
            "Epoch 49/50\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9955 - val_loss: 0.4752 - val_accuracy: 0.8393\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.24112\n",
            "Epoch 50/50\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9955 - val_loss: 0.4704 - val_accuracy: 0.9107\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.24112\n",
            "Training completed in time:  0:00:10.693805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrYsuH8BdZtT",
        "outputId": "0cafb218-6bd5-498e-acdf-f12424103f02"
      },
      "source": [
        "score = model.evaluate(X_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  1.0\n",
            "Testing Accuracy:  0.9107142686843872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4v8ShYMijjY",
        "outputId": "daa7cda3-7f33-470a-8400-eb07b8dee6fd"
      },
      "source": [
        "features=[]\n",
        "import numpy as np\n",
        "data=extract_features('/content/drive/MyDrive/full_dataset/dog_barking_99.wav')\n",
        "features.append([data])\n",
        "df_features=pd.DataFrame(features,columns=['feature'])\n",
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(df_features.feature.tolist())\n",
        "X=X.reshape(X.shape[0],n_rows,n_cols,n_channels)\n",
        "model.predict(X)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00116674, 0.99883324]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Vjaxtpi4y1",
        "outputId": "c7b02c2c-72c7-4bdc-c972-e6d0000c7ed0"
      },
      "source": [
        "features=[]\n",
        "import numpy as np\n",
        "data=extract_features('/content/drive/MyDrive/full_dataset/cat_156.wav')\n",
        "features.append([data])\n",
        "df_features=pd.DataFrame(features,columns=['feature'])\n",
        "# Convert features and corresponding classification labels into numpy arrays\n",
        "X = np.array(df_features.feature.tolist())\n",
        "X=X.reshape(X.shape[0],n_rows,n_cols,n_channels)\n",
        "model.predict(X)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9993813e-01, 6.1812127e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W7bUp4qou5p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}